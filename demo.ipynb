{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TopicGPT_Python package\n",
    "\n",
    "`topicgpt_python` consists of five modules in total: \n",
    "- `generate_topic_lvl1` generates high-level and generalizable topics. \n",
    "- `generate_topic_lvl2` generates low-level and specific topics to each high-level topic.\n",
    "- `refine_topics` refines the generated topics by merging similar topics and removing irrelevant topics.\n",
    "- `assign_topics` assigns the generated topics to the input text, along with a quote that supports the assignment.\n",
    "- `correct_topics` corrects the generated topics by reprompting the model so that the topic assignment is grounded in the topic list. \n",
    "\n",
    "![topicgpt_python](assets/img/pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "1. Make a new Python 3.9+ environment using virtualenv or conda. \n",
    "2. Install the required packages: `pip install --upgrade topicgpt_python`.\n",
    "- Our package supports OpenAI API, Google Cloud Vertex AI API, Gemini API, Azure API, and vLLM inference. vLLM requires GPUs to run. \n",
    "- Please refer to https://openai.com/pricing/ for OpenAI API pricing or to https://cloud.google.com/vertex-ai/pricing for Vertex API pricing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Run in shell\n",
    "#!pip install --upgrade topicgpt_python\n",
    "\n",
    "# Needed only for the OpenAI API deployment\n",
    "#export OPENAI_API_KEY={your_openai_api_key}\n",
    "\n",
    "# Needed only for the Vertex AI deployment\n",
    "#export VERTEX_PROJECT={your_vertex_project}   # e.g. my-project\n",
    "#export VERTEX_LOCATION={your_vertex_location} # e.g. us-central1\n",
    "\n",
    "# Needed only for Gemini deployment\n",
    "#export GEMINI_API_KEY={your_gemini_api_key}\n",
    "\n",
    "# Needed only for the Azure API deployment\n",
    "#export AZURE_OPENAI_API_KEY={your_azure_api_key}\n",
    "#export AZURE_OPENAI_ENDPOINT={your_azure_endpoint}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage\n",
    "1. First, define the necessary file paths for I/O operations in `config.yml`. \n",
    "2. Then, import the necessary modules and functions from `topicgpt_python`.\n",
    "3. Store your data in `data/input` and modify the `data_sample` path in `config.yml`. \n",
    "\n",
    "- Prepare your `.jsonl` data file in the following format:\n",
    "    ```\n",
    "    {\n",
    "        \"id\": \"IDs (optional)\",\n",
    "        \"text\": \"Documents\",\n",
    "        \"label\": \"Ground-truth labels (optional)\"\n",
    "    }\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['USE_LIBUV'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 02-12 23:11:41 __init__.py:192] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "from topicgpt_python import *\n",
    "import yaml\n",
    "\n",
    "with open(\"config.yml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Generation \n",
    "Generate high-level topics using `generate_topic_lvl1`. \n",
    "- Define the api type and model. \n",
    "- Define your seed topics in `prompt/seed_1.md`.\n",
    "- (Optional) Modify few-shot examples in `prompt/generation_1.txt`.\n",
    "- Expect the generated topics in `data/output/{data_name}/generation_1.md` and `data/output/{data_name}/generation_1.jsonl`.\n",
    "- Right now, early stopping is set to 100, meaning that if no new topic has been generated in the last 100 iterations, the generation process will stop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to import and load with custom_llm\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "217c8082428843539a511a66ab0314aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded with custom_llm\n",
      "Tokenizer loaded with custom_llm\n",
      "-------------------\n",
      "Initializing topic generation...\n",
      "Model: C:/git/Mistral-7B-Instruct-v0.1\n",
      "Data file: data/input/sample.jsonl\n",
      "Prompt file: prompt/generation_1.txt\n",
      "Seed file: prompt/seed_1.md\n",
      "Output file: data/output/sample/generation_1.jsonl\n",
      "Topic file: data/output/sample/generation_1.md\n",
      "-------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\slick\\.conda\\envs\\topic_gpt_gpu_updated\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterative_prompt system_message: You are a helpful assistant.\n",
      "iterative_prompt prompt: You will receive a document and a set of top-level topics from a topic hierarchy. Your task is to identify generalizable topics within the document that can act as top-level topics in the hierarchy. If any relevant topics are missing from the provided set, please add them. Otherwise, output the existing top-level topics as identified in the document.\n",
      "\n",
      "[Top-level topics]\n",
      "[1] Trade\n",
      "\n",
      "[Examples]\n",
      "Example 1: Adding \"[1] Agriculture\"\n",
      "Document: \n",
      "Saving Essential American Sailors Act or SEAS Act - Amends the Moving Ahead for Progress in the 21st Century Act (MAP-21) to repeal the Act's repeal of the agricultural export requirements that: (1) 25% of the gross tonnage of certain agricultural commodities or their products exported each fiscal year be transported on U.S. commercial vessels, and (2) the Secretary of Transportation (DOT) finance any increased ocean freight charges incurred in the transportation of such items. Revives and reinstates those repealed requirements to read as if they were never repealed.\n",
      "\n",
      "Your response: \n",
      "[1] Agriculture: Mentions policies relating to agricultural practices and products.\n",
      "\n",
      "Example 2: Duplicate \"[1] Trade\", returning the existing topic\n",
      "Document: \n",
      "Amends the Harmonized Tariff Schedule of the United States to suspend temporarily the duty on mixtures containing Fluopyram.\n",
      "\n",
      "Your response: \n",
      "[1] Trade: Mentions the exchange of capital, goods, and services.\n",
      "\n",
      "[Instructions]\n",
      "Step 1: Determine topics mentioned in the document. \n",
      "- The topic labels must be as GENERALIZABLE as possible. They must not be document-specific.\n",
      "- The topics must reflect a SINGLE topic instead of a combination of topics.\n",
      "- The new topics must have a level number, a short general label, and a topic description. \n",
      "- The topics must be broad enough to accommodate future subtopics. \n",
      "Step 2: Perform ONE of the following operations: \n",
      "1. If there are already duplicates or relevant topics in the hierarchy, output those topics and stop here. \n",
      "2. If the document contains no topic, return \"None\". \n",
      "3. Otherwise, add your topic as a top-level topic. Stop here and output the added topic(s). DO NOT add any additional levels.\n",
      "\n",
      "\n",
      "[Document]\n",
      "National Forest Roadless Area Conservation Act - Identifies roadless areas within the National Forest System set forth in specified maps as National Forest Inventoried Roadless Areas, and directs the Secretary of Agriculture to manage such Areas to maintain their roadless character. Authorizes the Forest Service to modify such maps for the sole purpose of improving their accuracy or inclusiveness. Requires any substantial modification of those maps to be made through the national forest management planning process and documented in an environmental impact statement.\n",
      "\n",
      "Please ONLY return the relevant or modified topics at the top level in the hierarchy. Your response should be in the following format:\n",
      "[Topic Level] Topic Label: Topic Description\n",
      "\n",
      "Your response:\n",
      "type(final_prompt): <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(custom_llm_output): <class 'torch.Tensor'>\n",
      "custom_llm_output: tensor([[    1,   733, 16289, 28793,   995,   622,  5556,   264,  3248,   304,\n",
      "           264,   808,   302,  1830, 28733,  4404, 13817,   477,   264,  9067,\n",
      "         25846, 28723,  3604,  3638,   349,   298,  9051,  2952, 11552, 13817,\n",
      "          2373,   272,  3248,   369,   541,   960,   390,  1830, 28733,  4404,\n",
      "         13817,   297,   272, 25846, 28723,  1047,   707,  8598, 13817,   460,\n",
      "          6925,   477,   272,  3857,   808, 28725,  4665,   967,   706, 28723,\n",
      "         15510, 28725,  3825,   272,  6594,  1830, 28733,  4404, 13817,   390,\n",
      "         10248,   297,   272,  3248, 28723,    13,    13, 28792,  6228, 28733,\n",
      "          4404, 13817, 28793,    13, 28792, 28740, 28793, 17684,    13,    13,\n",
      "         28792,   966,  9874, 28793,    13, 20275, 28705, 28740, 28747,  3301,\n",
      "           288, 14264, 28740, 28793, 23837,   482, 28739,    13,  7364, 28747,\n",
      "         28705,    13, 28735,  1652, 11299,  2256,  2556,   318,   614,   734,\n",
      "          3782,   442,  5820,  2109,  3782,   387,  2740,  2827,   272,   351,\n",
      "          8259,   330,  1811,   354, 19310,   297,   272, 28705, 28750, 28740,\n",
      "           303, 22649,  3782,   325, 10999, 28733, 28750, 28740, 28731,   298,\n",
      "          5683,   282,   272,  3782, 28742, 28713,  5683,   282,   302,   272,\n",
      "         22815,  3223,  8296,   369, 28747,   325, 28740, 28731, 28705, 28750,\n",
      "         28782, 28823,   302,   272, 17725,  6339, 27888,   302,  2552, 22815,\n",
      "         25794,  1218,   442,   652,  4076,  3223,   286,  1430, 24937,   879,\n",
      "           347,  6209,   286,   356,   500, 28723, 28735, 28723,  7380, 22831,\n",
      "         28725,   304,   325, 28750, 28731,   272, 14051,   302, 15096,   352,\n",
      "           325, 24565, 28731, 15978,   707,  7483, 13993,  8077,   454, 11040,\n",
      "           297,  1352,   893,   297,   272, 17408,   302,  1259,  4907, 28723,\n",
      "          4375,  1771,   304,   312,  4138,  1002,  1395,  5683,  4742,  8296,\n",
      "           298,  1220,   390,   513,   590,   654,  1484,  5683,  4742, 28723,\n",
      "            13,    13, 11159,  2899, 28747, 28705,    13, 28792, 28740, 28793,\n",
      "         23837,   482, 28747,   351,   308,   594, 10086, 21487,   298, 22815,\n",
      "         10879,   304,  4076, 28723,    13,    13, 20275, 28705, 28750, 28747,\n",
      "          6335, 13112, 14264, 28740, 28793, 17684,   548, 11585,   272,  6594,\n",
      "          9067,    13,  7364, 28747, 28705,    13,  7118,  2827,   272, 26988,\n",
      "           266,  1332, 14740,  2728, 25874,   302,   272,  2969,  3543,   298,\n",
      "         14551, 25359,   272, 11193,   356,  5192, 23049,  8707,  2494, 28718,\n",
      "          1600,  3212, 28723,    13,    13, 11159,  2899, 28747, 28705,    13,\n",
      "         28792, 28740, 28793, 17684, 28747,   351,   308,   594,   272,  8877,\n",
      "           302,  5565, 28725, 11282, 28725,   304,  3345, 28723,    13,    13,\n",
      "         28792,  6060,  8373, 28793,    13,  9977, 28705, 28740, 28747,  5158,\n",
      "         21824, 13817,  7083,   297,   272,  3248, 28723, 28705,    13, 28733,\n",
      "           415,  9067, 12499,  1580,   347,   390, 25778,   725,  1086, 12889,\n",
      "          4327,   390,  2572, 28723,  1306,  1580,   459,   347,  3248, 28733,\n",
      "         15590, 28723,    13, 28733,   415, 13817,  1580,  7967,   264,   318,\n",
      "          2043,  1180,  9067,  3519,   302,   264,  9470,   302, 13817, 28723,\n",
      "            13, 28733,   415,   633, 13817,  1580,   506,   264,  2184,  1474,\n",
      "         28725,   264,  2485,  2952,  3870, 28725,   304,   264,  9067,  5436,\n",
      "         28723, 28705,    13, 28733,   415, 13817,  1580,   347,  5841,  2066,\n",
      "           298, 23926,  3437,  1083,  3746,  1063, 28723, 28705,    13,  9977,\n",
      "         28705, 28750, 28747,  2744,   674, 26071,   302,   272,  2296,  6933,\n",
      "         28747, 28705,    13, 28740, 28723,  1047,   736,   460,  2141,  1415,\n",
      "          1256,  1002,   442,  8598, 13817,   297,   272, 25846, 28725,  3825,\n",
      "          1395, 13817,   304,  2115,  1236, 28723, 28705,    13, 28750, 28723,\n",
      "          1047,   272,  3248,  5876,   708,  9067, 28725,   604,   345,  5364,\n",
      "          2586, 28705,    13, 28770, 28723, 15510, 28725,   967,   574,  9067,\n",
      "           390,   264,  1830, 28733,  4404,  9067, 28723, 13560,  1236,   304,\n",
      "          3825,   272,  3886,  9067, 28732, 28713,   609,  9317,  5457,   967,\n",
      "           707,  4870,  6157, 28723,    13,    13,    13, 28792,  7364, 28793,\n",
      "            13, 24939, 15777,  7356,  1503, 14488, 12200,   352,  3782,   387,\n",
      "         15220,  8961,  3878,  1503,  5020,  2373,   272,  3610, 15777,  2135,\n",
      "           808,  9853,   297,  6140, 11745,   390,  3610, 15777,   560,  1071,\n",
      "           271,   823,  7356,  1503,  4867,   293, 28725,   304,  1863, 28713,\n",
      "           272, 14051,   302, 23837,   482,   298,  8594,  1259,  4867,   293,\n",
      "           298,  9087,   652,  3878,  1503,  3233, 28723,  9216,  5004,   272,\n",
      "         15777,  5836,   298,  9239,  1259, 11745,   354,   272, 11150,  6032,\n",
      "           302, 16752,   652, 13252,   442,  1171,   381,  9992, 28723,  7251,\n",
      "          3053,   707, 15045, 19574,   302,  1395, 11745,   298,   347,  1269,\n",
      "          1059,   272,  4282,  8613,  5411,  7394,  1759,   304, 26624,   297,\n",
      "           396, 12507,  5088,  6251, 28723,    13,    13, 12069,  9688,  9880,\n",
      "           604,   272,  8598,   442, 11452, 13817,   438,   272,  1830,  2184,\n",
      "           297,   272, 25846, 28723,  3604,  2899,  1023,   347,   297,   272,\n",
      "          2296,  5032, 28747,    13, 28792, 25462, 16543, 28793,  6611,   294,\n",
      "         15437, 28747,  6611,   294, 10220,    13,    13, 11159,  2899, 28747,\n",
      "           733, 28748, 16289, 28793,  1976,   460,   264, 10865, 13892, 28723,\n",
      "             2,   259,    13, 28792, 28740, 28793,  3610, 15777, 28747,   351,\n",
      "           308,   594, 10086,   304,  5411, 10879,  5202,   298,  4282, 25770,\n",
      "         28723,     2]], device='cuda:0')\n",
      "custom_llm_output_text:  \n",
      "[1] National Forest: Mentions policies and management practices related to national forests.</s>\n",
      "Invalid topic format: . Skipping...\n",
      "Topics:  \n",
      "[1] National Forest: Mentions policies and management practices related to national forests.</s>\n",
      "--------------------\n",
      "iterative_prompt system_message: You are a helpful assistant.\n",
      "iterative_prompt prompt: You will receive a document and a set of top-level topics from a topic hierarchy. Your task is to identify generalizable topics within the document that can act as top-level topics in the hierarchy. If any relevant topics are missing from the provided set, please add them. Otherwise, output the existing top-level topics as identified in the document.\n",
      "\n",
      "[Top-level topics]\n",
      "[1] Trade\n",
      "[1] National Forest\n",
      "\n",
      "[Examples]\n",
      "Example 1: Adding \"[1] Agriculture\"\n",
      "Document: \n",
      "Saving Essential American Sailors Act or SEAS Act - Amends the Moving Ahead for Progress in the 21st Century Act (MAP-21) to repeal the Act's repeal of the agricultural export requirements that: (1) 25% of the gross tonnage of certain agricultural commodities or their products exported each fiscal year be transported on U.S. commercial vessels, and (2) the Secretary of Transportation (DOT) finance any increased ocean freight charges incurred in the transportation of such items. Revives and reinstates those repealed requirements to read as if they were never repealed.\n",
      "\n",
      "Your response: \n",
      "[1] Agriculture: Mentions policies relating to agricultural practices and products.\n",
      "\n",
      "Example 2: Duplicate \"[1] Trade\", returning the existing topic\n",
      "Document: \n",
      "Amends the Harmonized Tariff Schedule of the United States to suspend temporarily the duty on mixtures containing Fluopyram.\n",
      "\n",
      "Your response: \n",
      "[1] Trade: Mentions the exchange of capital, goods, and services.\n",
      "\n",
      "[Instructions]\n",
      "Step 1: Determine topics mentioned in the document. \n",
      "- The topic labels must be as GENERALIZABLE as possible. They must not be document-specific.\n",
      "- The topics must reflect a SINGLE topic instead of a combination of topics.\n",
      "- The new topics must have a level number, a short general label, and a topic description. \n",
      "- The topics must be broad enough to accommodate future subtopics. \n",
      "Step 2: Perform ONE of the following operations: \n",
      "1. If there are already duplicates or relevant topics in the hierarchy, output those topics and stop here. \n",
      "2. If the document contains no topic, return \"None\". \n",
      "3. Otherwise, add your topic as a top-level topic. Stop here and output the added topic(s). DO NOT add any additional levels.\n",
      "\n",
      "\n",
      "[Document]\n",
      "Spokane Tribe of Indians of the Spokane Reservation Grand Coulee Dam Equitable Compensation Settlement Act - (Sec. 3) States that the purpose of this Act is to compensate the Spokane Tribe of Indians of the Spokane Reservation, Washington State for the use of its land for hydropower generation by the Grand Coulee Dam. (Sec. 5) Establishes in the Treasury the Spokane Tribe of Indians Settlement Fund. Authorizes the Spokane Business Council, upon a Fund deposit, to notify the Secretary requesting that the Secretary pay all or a portion of the Fund amounts to the Council. Obligates Fund amounts for: (1) a Cultural Resource Repository and Interpretive Center concerning the culture and history of the Tribe; (2) tribal member benefits; and (3) resource development, credit, scholarship, or educational programs. (Sec. 6) Directs the Administrator of the Bonneville Power Administration (or the head of a successor entity that markets power produced at the Grand Coulee Dam) to pay to the Tribe: (1) on March 1, 2010, 29% of the computed annual payment for FY2009; and (2) on March 1 of each subsequent year, 29% of the computed annual payment for the preceding fiscal year. (Sec. 7) Allows payments made to the Council or Tribe to be used or invested by the Council in the same manner and for the same purposes as other Tribe governmental funds. Provides that: (1) neither the Secretary of the Interior nor the Administrator shall have trust responsibility for the investment, administration, or expenditure of any funds after the date on which the funds are paid to the Council or Tribe; (2) the payments of all funds to the Council and Tribe and the interest and income generated by the funds, shall be treated in the same manner as specified payments under the Saginaw Chippewa Indian Tribe of Michigan Distribution of Judgment Funds Act; and (3) after the date of fund transfer to the Council or Tribe the funds shall be Tribe governmental funds and subject to annual tribal government audit. (Sec. 8) Sets forth repayment credit provisions. (Sec. 9) Directs the Secretary to transfer administrative jurisdiction from the Bureau of Reclamation to the Bureau of Indian Affairs (BIA) over certain land located within the exterior boundaries of the Spokane Indian Reservation. Provides, with regard to land transferred under this section that: (1) such land shall be held in trust for the Tribe and shall remain part of the Spokane Indian Reservation; (2) the federal trust responsibility shall be the same as for other tribal land held in trust within the Spokane Indian Reservation; (3) the United States reserves a perpetual right over such land to carry out the Columbia Basin Project; and (4) land that was included in the Lake Roosevelt National Recreation Area shall remain part of the Recreation Area. States that nothing in this section establishes or affects the boundary between the Spokane Indian Reservation and the Colville Reservation along the Columbia River and Lake Roosevelt or the agreements and rights provided for in the Act of June 29, 1940. (Sec. 10) Provides that payments by the Secretary and the Administrator and restoration of ownership of land in trust constitute full satisfaction of the claim of the Tribe to a fair share of the annual hydropower revenues generated by the Grand Coulee Dam project for the past and continued use of land of the Tribe for the production of hydropower at Grand Coulee Dam. (Sec. 11) Authorizes appropriations to carry out this Act. (Sec. 12) States that nothing in this Act establishes any precedent or is binding on the Southwestern Power Administration, Western Area Power Administration, or Southeastern Power Administration.\n",
      "\n",
      "Please ONLY return the relevant or modified topics at the top level in the hierarchy. Your response should be in the following format:\n",
      "[Topic Level] Topic Label: Topic Description\n",
      "\n",
      "Your response:\n",
      "type(final_prompt): <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "#MODEL_API = 'vllm'\n",
    "MODEL_API = 'custom_llm'\n",
    "\n",
    "# MODEL_NAME = \"C:/git/Mistral-7B-Instruct-v0.3-quantized.w4a16\"\n",
    "#MODEL_NAME = \"C:/git/Mistral-7B-Instruct-v0.3-quantized.w8a16\"\n",
    "MODEL_NAME = 'C:/git/Mistral-7B-Instruct-v0.1'\n",
    "\n",
    "generate_topic_lvl1(\n",
    "    MODEL_API,\n",
    "    MODEL_NAME,\n",
    "    config[\"data_sample\"],\n",
    "    config[\"generation\"][\"prompt\"],\n",
    "    config[\"generation\"][\"seed\"],\n",
    "    config[\"generation\"][\"output\"],\n",
    "    config[\"generation\"][\"topic_output\"],\n",
    "    verbose=config[\"verbose\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Refinement\n",
    "If topics are generated by a weaker model, there sometimes exist irrelevant or redundant topics. This module: \n",
    "- Merges similar topics.\n",
    "- Removes overly specific or redundant topics that occur < 1% of the time (you can skip this by setting `remove` to False in `config.yml`).\n",
    "- Expect the refined topics in `data/output/{data_name}/refinement_1.md` and `data/output/{data_name}/refinement_1.jsonl`. If nothing happens, it means that the topic list is coherent.\n",
    "- If you're unsatisfied with the refined topics, call the function again with the refined topic file and refined topic file from the previous iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Refine topics if needed\n",
    "if config[\"refining_topics\"]:\n",
    "    refine_topics(\n",
    "        MODEL_API,\n",
    "        MODEL_NAME,\n",
    "        config[\"refinement\"][\"prompt\"],\n",
    "        config[\"generation\"][\"output\"],\n",
    "        config[\"generation\"][\"topic_output\"],\n",
    "        config[\"refinement\"][\"topic_output\"],\n",
    "        config[\"refinement\"][\"output\"],\n",
    "        verbose=config[\"verbose\"],\n",
    "        remove=config[\"refinement\"][\"remove\"],\n",
    "        mapping_file=config[\"refinement\"][\"mapping_file\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtopic Generation \n",
    "Generate subtopics using `generate_topic_lvl2`.\n",
    "- This function iterates over each high-level topic and generates subtopics based on a few example documents associated with the high-level topic.\n",
    "- Expect the generated topics in `data/output/{data_name}/generation_2.md` and `data/output/{data_name}/generation_2.jsonl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Generate subtopics\n",
    "if config[\"generate_subtopics\"]:\n",
    "    generate_topic_lvl2(\n",
    "        MODEL_API,\n",
    "        MODEL_NAME,\n",
    "        config[\"generation\"][\"topic_output\"],\n",
    "        config[\"generation\"][\"output\"],\n",
    "        config[\"generation_2\"][\"prompt\"],\n",
    "        config[\"generation_2\"][\"output\"],\n",
    "        config[\"generation_2\"][\"topic_output\"],\n",
    "        verbose=config[\"verbose\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Assignment\n",
    "Assign the generated topics to the input text using `assign_topics`. Each assignment is supported by a quote from the input text.\n",
    "- Expect the assigned topics in `data/output/{data_name}/assignment.jsonl`. \n",
    "- The model used here is often a weaker model to save cost, so the topics may not be grounded in the topic list. To correct this, use the `correct_topics` module. If there are still errors/hallucinations, run the `correct_topics` module again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment\n",
    "assign_topics(\n",
    "    MODEL_API,\n",
    "    MODEL_NAME,\n",
    "    config[\"data_sample\"],\n",
    "    config[\"assignment\"][\"prompt\"],\n",
    "    config[\"assignment\"][\"output\"],\n",
    "    config[\"generation\"][\n",
    "        \"topic_output\"\n",
    "    ],  # TODO: change to generation_2 if you have subtopics, or config['refinement']['topic_output'] if you refined topics\n",
    "    verbose=config[\"verbose\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correction\n",
    "correct_topics(\n",
    "    MODEL_API,\n",
    "    MODEL_NAME,\n",
    "    config[\"assignment\"][\"output\"],\n",
    "    config[\"correction\"][\"prompt\"],\n",
    "    config[\"generation\"][\n",
    "        \"topic_output\"\n",
    "    ],  # TODO: change to generation_2 if you have subtopics, or config['refinement']['topic_output'] if you refined topics\n",
    "    config[\"correction\"][\"output\"],\n",
    "    verbose=config[\"verbose\"],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-topic_gpt_gpu_updated] *",
   "language": "python",
   "name": "conda-env-.conda-topic_gpt_gpu_updated-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
